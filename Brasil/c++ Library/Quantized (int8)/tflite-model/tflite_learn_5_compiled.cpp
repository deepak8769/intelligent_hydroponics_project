/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 13.11.2023 05:15:38

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#elif defined __ICCARM__
#define ALIGN(x) __attribute__((aligned(x)))
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#ifndef CONFIG_IDF_TARGET_ESP32S3
#define EI_MAX_SCRATCH_BUFFER_COUNT 8
#else
#define EI_MAX_SCRATCH_BUFFER_COUNT 16
#endif // CONFIG_IDF_TARGET_ESP32S3
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX) || defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
constexpr int kTensorArenaSize = 141472;
#else
constexpr int kTensorArenaSize = 140448;
#endif

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_CONV_2D, OP_MAX_POOL_2D, OP_RESHAPE, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

typedef struct {
  TfLiteTensor tensor;
  int16_t index;
} TfLiteTensorWithIndex;

typedef struct {
  TfLiteEvalTensor tensor;
  int16_t index;
} TfLiteEvalTensorWithIndex;

TfLiteContext ctx{};
static const int MAX_TFL_TENSOR_COUNT = 4;
static TfLiteTensorWithIndex tflTensors[MAX_TFL_TENSOR_COUNT];
static const int MAX_TFL_EVAL_COUNT = 4;
static TfLiteEvalTensorWithIndex tflEvalTensors[MAX_TFL_EVAL_COUNT];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[11];

const TfArray<4, int> tensor_dimension0 = { 4, { 1,96,96,3 } };
const TfArray<1, float> quant0_scale = { 1, { 0.0039215688593685627, } };
const TfArray<1, int> quant0_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(8) int32_t tensor_data1[2] = { -1, 288, };
const TfArray<1, int> tensor_dimension1 = { 1, { 2 } };
const ALIGN(8) int32_t tensor_data2[3] = { -772, 969, -226, };
const TfArray<1, int> tensor_dimension2 = { 1, { 3 } };
const TfArray<1, float> quant2_scale = { 1, { 0.00014888324949424714, } };
const TfArray<1, int> quant2_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant2 = { (TfLiteFloatArray*)&quant2_scale, (TfLiteIntArray*)&quant2_zero, 0 };
const ALIGN(16) int8_t tensor_data3[3*288] = { 
  -25, -20, -5, -11, -40, 0, -15, -9, -13, 6, 28, -8, -5, -12, 1, -27, -36, -43, 34, 32, 11, -8, -33, -77, -51, -23, 40, -11, 51, 17, -44, -105, -70, -26, 13, 14, 52, 14, -62, -80, -34, -22, 23, 6, 4, -2, -38, -106, -21, 6, -11, -22, -29, 29, 59, -1, -7, -28, 10, 18, 26, -1, 57, -22, -21, 3, 6, -1, -10, -18, 24, -13, -8, -24, 3, 18, 17, -20, 75, -35, -2, 25, 17, -8, 0, -14, 47, 11, -25, -5, 0, 19, 24, -19, 75, 15, -1, -16, 22, -11, 25, 1, 35, 30, -22, -28, -9, 48, 31, 31, 22, 4, 1, -29, 21, 11, -2, 26, 29, -6, -24, -6, 47, -2, 7, 15, -35, 49, -19, -23, 48, 9, 15, -16, 12, -19, -7, -24, 43, 18, 28, -2, -9, 4, 10, -35, 32, -25, 3, 29, -54, -7, -14, -61, -6, 29, 10, 9, -34, 8, -10, -41, 27, 32, 16, 46, -51, -23, -31, -11, 21, -9, 38, 26, -38, 3, -25, -6, 31, 31, 14, -35, -99, 49, -18, -17, -15, 27, 18, 18, -37, -55, -25, -30, -7, -13, 12, -50, 8, 34, -38, -16, 18, 3, 40, -20, -68, 15, -46, -32, 14, 36, 17, 18, -127, -26, -46, -60, -2, 29, 48, -15, -47, 88, -30, -16, 25, 7, 9, 22, -66, -13, -12, -20, -26, 16, 17, -61, -80, 20, -64, -47, -19, -8, -21, -23, 11, -60, -28, -27, 5, 1, -15, 66, -13, -10, -36, -29, 22, 30, 36, -4, -72, -16, -56, -77, 10, 8, 7, 28, 33, 14, -24, 4, -1, 12, 54, -38, 56, -17, -34, -36, -43, -31, -1, -69, 65, 15, 
  -15, 54, -48, -1, 4, 12, 13, 13, 0, 6, -34, -51, -36, 1, -14, 3, -8, 34, -80, -65, -48, -50, -20, 15, 23, 26, -45, -7, -29, -14, 0, 32, 38, 9, -33, -47, 3, -26, 26, 43, 47, 11, -30, -63, -29, -24, 61, 36, -17, 28, -33, 18, -38, 16, -14, 28, -13, 12, -116, -66, -34, 13, -21, -4, 10, -13, -100, -89, -42, -4, 12, -10, 67, 3, -84, -48, -58, 36, 16, 20, 44, -15, -58, -39, -48, -45, 36, 31, 46, 8, -100, -33, -33, -27, 27, 41, 53, 20, -69, -11, -42, 24, 43, -13, 44, -16, -78, -92, -21, -49, 40, 23, 24, -16, -119, -107, -49, -36, -37, 47, 32, -20, -90, -82, -93, -46, 32, 27, 7, -25, -76, -92, -65, 6, 17, 31, 54, -23, -102, -103, -64, -12, 12, 16, 42, 56, -96, 19, -67, -43, 19, 19, 29, 18, -79, -75, -53, -78, -1, -8, 25, 9, -70, -92, -99, -39, 42, 16, 45, -1, -60, -80, -89, -13, 61, 1, 28, 2, -110, -65, -59, -42, 21, 20, 11, -5, -103, -98, -90, -95, -21, 39, 31, 10, -38, 12, -8, 28, 17, 21, 11, 51, -95, -82, -81, -63, -26, -14, 54, 19, -60, -79, -83, -104, 21, 76, 62, 16, -47, -53, -69, -36, 22, -2, 41, 41, -69, -56, -61, -41, -7, 42, 11, 6, -22, -47, -62, -3, 19, 17, 30, 39, -24, 17, -38, 2, 52, 21, 16, 28, -100, -54, -36, -12, -20, -25, 46, 0, -118, -71, -35, -53, 44, 34, 32, 2, -87, -71, -57, -66, 30, -44, 15, 0, -66, -78, -42, -25, -10, 10, 5, 16, -58, -2, -36, -7, 18, -22, 
  -22, 5, 2, 7, -4, -11, -5, 12, 11, -7, 12, -26, 33, 7, 11, 30, -10, 1, 26, 7, -10, 5, -16, 15, 47, 8, 19, -5, 4, 30, 6, 70, 39, -2, 11, 32, -26, -5, 24, 79, 36, 18, -9, -9, -32, 17, 29, 77, -25, -12, 6, -17, -5, -11, -56, -14, -6, -7, -1, -3, -14, -20, -35, 23, 27, -15, -6, -19, -34, -6, -60, -14, 10, -8, 5, 0, -8, -15, -54, 55, 14, -39, 12, -10, -11, 25, -71, -15, -23, 6, 0, 21, 5, -10, -91, -7, -4, -25, 12, -2, 8, 27, -12, -37, -25, 8, -19, 23, -10, -11, -15, -25, -1, -4, 4, 1, -19, 27, 14, -18, -21, 17, 32, -14, 0, -20, 0, -64, -52, 0, 26, 1, 32, -16, 21, -5, -47, 14, 6, -27, 21, -45, -8, 21, 14, -3, 32, -12, 20, 10, 48, -9, -20, 55, -5, 37, -5, -12, 35, -31, 0, 51, 11, 8, -13, -18, 5, 27, -23, 36, 7, -14, 7, -24, 18, 15, 9, -1, 32, 15, -5, 17, 89, -17, 4, 44, -15, 17, -7, 23, 34, -1, -2, -2, 20, 10, 14, 54, 48, 2, 8, -23, -10, 1, 26, -18, 94, 37, 30, 22, 7, 12, -9, -26, 105, -36, 19, 29, -11, 21, -9, 2, 37, -67, -27, 10, 26, -2, 2, 34, 56, 17, -12, -18, 2, -6, 5, 55, 28, -10, 62, -7, -2, 32, 37, 21, -22, 24, 20, -37, 13, -18, 7, -59, -6, 15, 7, -18, 29, 35, -33, 16, 9, 10, 20, 39, 7, 11, -14, -7, 9, -40, 17, 10, 28, 3, -5, 13, -54, -35, 4, -22, 28, 22, 34, 87, -93, 12, 
};
const TfArray<2, int> tensor_dimension3 = { 2, { 3,288 } };
const TfArray<1, float> quant3_scale = { 1, { 0.0046169105917215347, } };
const TfArray<1, int> quant3_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant3 = { (TfLiteFloatArray*)&quant3_scale, (TfLiteIntArray*)&quant3_zero, 0 };
const ALIGN(16) int32_t tensor_data4[8] = { 1628, 1911, -2432, -2063, -2522, -2597, -786, 15, };
const TfArray<1, int> tensor_dimension4 = { 1, { 8 } };
const TfArray<8, float> quant4_scale = { 8, { 4.8921243433142081e-05, 4.9545458750799298e-05, 4.7726731281727552e-05, 4.5248001697473228e-05, 5.5645967222517356e-05, 5.3247978939907625e-05, 6.5576678025536239e-05, 6.0438258515205234e-05, } };
const TfArray<8, int> quant4_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant4 = { (TfLiteFloatArray*)&quant4_scale, (TfLiteIntArray*)&quant4_zero, 0 };
const ALIGN(16) int8_t tensor_data5[8*3*3*8] = { 
  /* [0][0][][] */ 13,-127,-4,35,-105,89,-49,-44, -21,-70,-89,-40,-39,46,56,-78, 65,45,-71,-17,-68,-8,-54,51, 
  /* [0][1][][] */ 110,23,18,-62,-82,9,47,56, 62,72,-17,-17,66,-50,29,-53, 67,60,-73,-15,-49,-50,58,21, 
  /* [0][2][][] */ 62,-45,-61,-23,-68,64,24,86, -7,-11,-86,-93,21,-46,35,35, -14,-26,41,-18,-81,57,95,105, 
  /* [1][0][][] */ -71,-47,-49,-74,-26,24,127,18, -49,42,-4,30,-91,83,86,75, 32,-31,-11,42,-91,-2,32,39, 
  /* [1][1][][] */ 9,57,-21,20,33,-25,53,58, 49,39,35,23,46,82,91,29, 8,39,-22,10,-61,25,2,-54, 
  /* [1][2][][] */ -60,14,-26,19,-9,90,13,63, -41,-21,9,16,-4,80,-29,70, -45,-6,8,-7,8,101,-28,-58, 
  /* [2][0][][] */ 2,22,-96,52,-39,33,-6,-74, 37,24,-13,-55,50,-48,-6,33, -8,-6,86,-24,13,67,-6,34, 
  /* [2][1][][] */ -8,35,-10,20,-30,-17,11,-79, -27,91,-38,10,78,-62,74,21, -15,75,103,-38,-13,-32,-56,71, 
  /* [2][2][][] */ -4,43,87,-60,-22,13,-6,7, 28,37,127,-56,122,6,15,41, -37,65,8,-77,36,-63,60,-14, 
  /* [3][0][][] */ -68,74,-15,-24,16,-44,12,-40, 22,-9,112,-2,1,77,-56,23, 58,-36,74,-28,65,33,-12,51, 
  /* [3][1][][] */ -56,48,100,-70,51,-35,17,-46, -7,60,54,36,69,-7,-33,86, -38,49,35,22,1,-71,-4,13, 
  /* [3][2][][] */ 30,31,25,-127,60,10,-24,-77, 0,-7,11,-26,41,90,55,22, -56,31,-28,-16,74,67,22,42, 
  /* [4][0][][] */ -25,56,48,-52,49,32,-83,-89, -2,66,59,-3,78,41,-40,15, 24,60,-1,-127,-25,2,-89,-7, 
  /* [4][1][][] */ 44,-38,44,-79,31,-52,-31,-5, -16,-6,-66,36,-52,-25,-72,-6, -41,11,-18,-124,52,-20,-32,62, 
  /* [4][2][][] */ -40,42,-52,-80,23,-26,-80,42, 39,-57,13,-6,19,-31,68,-23, 16,-6,53,-42,50,-6,57,-13, 
  /* [5][0][][] */ -46,-40,-31,-55,-45,-26,88,12, -1,-14,2,-95,69,-127,46,-68, 41,26,3,-57,3,-27,10,71, 
  /* [5][1][][] */ -33,-43,13,-39,-51,-11,66,54, -71,36,50,25,-37,-53,-19,32, 7,-14,47,11,75,57,-102,37, 
  /* [5][2][][] */ 44,-33,34,-15,-42,53,39,102, 63,84,-15,-90,73,50,-120,5, 70,-53,-8,-64,52,-16,-45,58, 
  /* [6][0][][] */ -67,18,26,-12,8,30,36,-35, -105,21,33,-36,16,-42,-43,-127, -94,-13,25,13,-6,-36,-69,-94, 
  /* [6][1][][] */ 35,-33,-33,-15,-38,-13,88,-12, 63,-51,-38,67,-124,-36,-22,8, -14,-60,-62,96,-98,36,-1,62, 
  /* [6][2][][] */ 60,13,-61,-25,56,58,78,39, 79,10,-48,-43,38,47,-62,-13, 43,91,26,-24,-7,58,41,82, 
  /* [7][0][][] */ -19,8,48,-6,64,-2,-93,45, 71,-39,-52,19,-15,-74,-127,-4, 58,-59,-38,14,17,34,-44,-62, 
  /* [7][1][][] */ -3,17,15,-58,42,-25,31,-5, 34,-104,-12,-18,-38,-18,93,60, -39,-88,-7,-43,-75,-27,94,39, 
  /* [7][2][][] */ 44,-95,-73,-46,-94,48,55,-17, -58,-68,-92,-46,-16,-55,76,39, 53,-9,8,9,-8,56,68,13, 
};
const TfArray<4, int> tensor_dimension5 = { 4, { 8,3,3,8 } };
const TfArray<8, float> quant5_scale = { 8, { 0.0030362820252776146, 0.0030750238802284002, 0.002962145023047924, 0.002808303339406848, 0.0034536500461399555, 0.0033048195764422417, 0.0040699965320527554, 0.0037510821130126715, } };
const TfArray<8, int> quant5_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant5 = { (TfLiteFloatArray*)&quant5_scale, (TfLiteIntArray*)&quant5_zero, 0 };
const ALIGN(16) int32_t tensor_data6[8] = { 1178, -2950, -4284, 4992, -5765, 3776, 3559, -912, };
const TfArray<1, int> tensor_dimension6 = { 1, { 8 } };
const TfArray<8, float> quant6_scale = { 8, { 2.7104104447062127e-05, 1.9336359400767833e-05, 1.8020760762738064e-05, 2.1359035599743947e-05, 1.9252123820479028e-05, 2.0629830032703467e-05, 2.244365714432206e-05, 2.5615350750740618e-05, } };
const TfArray<8, int> quant6_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int8_t tensor_data7[8*3*3*12] = { 
  /* [0][0][][] */ 39,14,41,-40,35,17,-5,-22,-9,-56,30,-53, 40,21,12,-26,-16,-23,27,-39,28,-26,46,28, 35,-13,46,-41,-79,10,-1,27,30,-96,-33,7, 
  /* [0][1][][] */ 41,-24,0,36,-56,-11,29,14,45,46,26,-50, 69,-50,27,67,-59,-40,26,8,47,6,55,-69, 87,-31,4,31,-59,-49,-11,-17,89,-4,17,-55, 
  /* [0][2][][] */ -44,-24,-88,6,-28,-1,-19,9,-28,35,-12,-11, -127,8,-46,55,45,-25,17,-65,-25,6,34,-28, -76,-36,-119,-25,-81,-33,-26,-24,-40,-32,37,-43, 
  /* [1][0][][] */ 90,-27,-87,39,5,49,12,40,57,14,-29,44, 38,-21,12,35,36,21,14,-36,-34,-17,-51,-26, -25,66,-61,25,68,59,-8,23,-68,70,9,18, 
  /* [1][1][][] */ -17,61,16,24,42,-50,-58,-27,90,-27,-47,18, -13,85,-47,-33,38,2,-33,61,16,-21,-12,49, 29,92,-2,-37,54,-56,70,84,-22,11,6,50, 
  /* [1][2][][] */ 17,79,-4,-2,31,2,48,127,90,-32,-3,80, 1,89,-57,70,49,-9,24,41,49,-52,67,-6, 86,111,10,37,69,-64,40,51,66,21,-39,-17, 
  /* [2][0][][] */ -68,-2,15,78,94,35,-11,91,54,-59,40,64, -74,4,-117,-2,31,60,50,61,0,38,-38,47, 32,67,-42,-48,113,24,-18,46,55,-5,25,107, 
  /* [2][1][][] */ -82,127,-47,55,57,-3,-68,96,-38,45,-93,98, -23,53,-32,-58,61,3,-10,73,69,-34,-10,89, 13,65,-32,35,85,78,36,97,-21,-60,-85,78, 
  /* [2][2][][] */ 101,17,18,27,77,48,-42,25,-67,25,-7,63, 47,106,-31,26,84,-61,14,123,-27,77,56,18, 31,9,-17,-40,80,28,-10,26,70,-64,-8,-46, 
  /* [3][0][][] */ 20,-75,43,-19,-92,-16,-100,-52,-53,-44,-13,-89, 50,1,-13,-92,46,-16,19,-68,-44,-36,9,-69, 43,-56,68,-13,-37,-50,-42,-127,-8,57,-28,-97, 
  /* [3][1][][] */ 45,-16,-23,-96,-62,-36,96,-106,59,-26,-67,-106, 27,-22,1,-67,40,57,73,-9,27,-6,-19,-61, -2,32,70,6,11,48,18,-51,70,67,43,-19, 
  /* [3][2][][] */ 56,-20,-30,52,-31,14,-56,-63,-49,-22,-7,-57, 12,-48,35,54,87,46,68,-48,37,-13,28,-58, -20,8,-28,46,20,33,-20,-44,-20,-76,-6,-6, 
  /* [4][0][][] */ 54,11,-127,7,57,-1,71,-6,39,-34,-63,50, 26,75,-4,-34,76,-25,22,47,-53,-22,-21,-22, 63,-16,-68,31,-16,-35,42,93,-56,-9,6,-2, 
  /* [4][1][][] */ 9,1,-61,-38,26,11,-61,61,79,4,-66,-7, 40,106,7,-71,15,-4,0,106,45,-23,21,6, 43,17,-34,16,68,-63,-29,94,11,31,-82,50, 
  /* [4][2][][] */ 12,53,-14,-29,71,-54,-66,111,59,15,9,35, 117,56,-120,-9,1,-47,17,92,28,-108,56,2, 32,-10,-125,-2,67,-10,103,13,-12,61,26,-7, 
  /* [5][0][][] */ 40,-61,-51,8,14,23,-8,40,41,84,-25,-74, 70,57,56,-66,-17,-16,-35,-29,43,73,28,-33, 127,30,-48,-38,18,43,16,-21,26,68,-12,-76, 
  /* [5][1][][] */ -22,-58,45,-31,-23,12,-75,22,10,-49,-6,-44, 33,-56,-15,10,73,-23,-32,-105,-28,81,-53,-1, 105,24,-6,-40,38,18,-56,-62,34,-32,-22,-35, 
  /* [5][2][][] */ 37,23,19,34,-43,30,-7,-64,11,-27,-9,-19, 2,-16,-34,-34,77,13,89,-87,62,79,83,66, 59,-59,-12,80,-42,30,36,23,5,-40,38,52, 
  /* [6][0][][] */ -29,-121,-68,28,-58,15,-16,-52,-54,103,13,-108, -127,12,-23,33,57,36,-33,13,-20,103,-1,9, -97,15,-24,-46,71,-73,63,-47,40,46,1,29, 
  /* [6][1][][] */ 22,-47,-50,-27,-33,45,-36,-88,-17,78,-72,-118, -48,13,-48,37,67,20,-44,-41,-28,59,-61,28, -84,-8,-28,-13,16,-23,101,-40,-25,68,36,69, 
  /* [6][2][][] */ 4,45,77,-2,-4,-25,-41,-54,-12,47,40,33, 56,-53,7,-41,-14,-39,-76,-15,69,4,-21,-46, 43,84,79,21,41,14,48,-14,-48,21,-43,1, 
  /* [7][0][][] */ -38,-3,-27,-29,-56,8,-40,33,-57,127,-56,-22, -13,-55,19,-33,18,-10,13,-44,17,13,25,2, 35,41,-40,15,32,-45,11,-33,22,18,47,13, 
  /* [7][1][][] */ 42,49,28,-79,49,30,6,11,4,24,-35,-58, -7,-34,-17,-17,83,-14,107,13,-50,47,-40,-7, 9,-23,-36,-20,1,30,19,-78,52,78,19,-26, 
  /* [7][2][][] */ 1,-4,45,-12,-32,-30,-45,-25,-45,8,-50,-36, -43,41,-25,16,93,19,81,-3,-40,101,40,65, -89,-60,21,-15,1,-60,-4,-59,-50,43,36,26, 
};
const TfArray<4, int> tensor_dimension7 = { 4, { 8,3,3,12 } };
const TfArray<8, float> quant7_scale = { 8, { 0.0038761845789849758, 0.0027653116267174482, 0.0025771667715162039, 0.0030545766931027174, 0.0027532652020454407, 0.0029502923134714365, 0.0032096893992275, 0.0036632765550166368, } };
const TfArray<8, int> quant7_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(16) int32_t tensor_data8[12] = { -3479, -860, 1306, -4159, -101, -4186, -3792, -2049, -3745, 3263, -1406, -814, };
const TfArray<1, int> tensor_dimension8 = { 1, { 12 } };
const TfArray<12, float> quant8_scale = { 12, { 1.582474033057224e-05, 1.8377182641415857e-05, 1.8546463252278045e-05, 1.6317557310685515e-05, 1.7593165466678329e-05, 1.0070418284158222e-05, 2.2277577954810113e-05, 1.5773068298585713e-05, 1.6566047634114511e-05, 2.8652826586039737e-05, 1.5765988791827112e-05, 2.3131977286539041e-05, } };
const TfArray<12, int> quant8_zero = { 12, { 0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(16) int8_t tensor_data9[12*3*3*12] = { 
  /* [0][0][][] */ 61,-95,5,-51,96,52,46,-104,37,104,-6,-91, 43,-59,-18,-76,70,12,4,-43,-67,12,-36,12, 67,11,33,-95,105,-67,12,-67,-63,-44,-99,-86, 
  /* [0][1][][] */ 44,-79,10,59,64,-44,-26,-13,-29,8,-2,-9, -50,-32,47,-63,3,-32,-51,-27,26,49,39,64, 75,-75,31,16,-13,-108,-50,-46,-106,-68,73,-53, 
  /* [0][2][][] */ 20,-62,-11,27,-48,-127,-81,65,-82,19,-14,14, -80,-110,39,67,-67,15,-98,102,-64,-72,56,97, 21,22,-91,53,-41,-81,-102,80,-96,-15,-27,-32, 
  /* [1][0][][] */ -81,24,20,41,64,-4,-53,-66,5,14,68,-31, -39,20,42,-21,50,-41,-14,-73,66,-16,9,60, -18,67,93,28,-76,-31,-124,38,8,23,30,3, 
  /* [1][1][][] */ -36,-39,20,1,73,25,-7,-64,69,51,65,37, -23,-54,58,36,-41,42,-77,24,-1,54,7,-51, 19,3,72,12,-43,20,-77,-47,-43,65,-9,48, 
  /* [1][2][][] */ 7,-67,59,14,-32,16,-36,24,45,69,42,22, -9,-10,59,19,8,-19,-44,-38,2,26,-24,-29, 39,39,51,-5,23,37,-127,43,-14,-7,-1,-44, 
  /* [2][0][][] */ 53,15,-27,7,43,-64,61,-15,22,6,19,25, 63,53,-15,-20,78,-86,5,20,65,-23,1,-56, 49,34,-9,-12,66,-67,35,-28,59,41,58,66, 
  /* [2][1][][] */ 70,-46,6,-7,127,-3,80,78,52,18,39,-27, 80,42,-62,42,-28,0,55,60,72,-19,12,9, 34,8,-53,36,100,-9,41,27,12,-62,45,29, 
  /* [2][2][][] */ -20,-24,-18,34,121,-40,86,-77,34,34,50,-46, 78,2,-67,-9,0,-29,32,-74,-66,23,33,-64, 86,-51,-12,-74,-15,-74,83,-104,33,-60,-47,-80, 
  /* [3][0][][] */ 61,49,-4,-2,42,4,-16,80,-89,-51,40,47, -8,-34,37,39,17,-14,-104,34,21,15,25,-3, 37,38,66,62,11,-67,-91,35,71,66,107,5, 
  /* [3][1][][] */ -12,-2,14,-28,26,17,-43,-16,-51,-83,-107,48, -34,-64,-29,9,127,24,25,-18,71,24,-37,-21, -25,55,43,69,44,-99,-14,7,-21,-30,-19,-41, 
  /* [3][2][][] */ 5,63,-24,-35,4,-32,5,31,-53,-13,-8,-49, 23,-4,-4,-17,24,21,66,-52,-13,-32,33,3, -55,-12,-25,-21,-112,-72,38,19,-42,50,-73,10, 
  /* [4][0][][] */ -36,21,85,65,43,34,-26,-35,40,76,11,-18, 11,-2,7,60,-20,43,-1,-68,6,71,29,-29, 39,8,64,38,65,65,-111,2,-37,70,-48,69, 
  /* [4][1][][] */ 29,22,72,-36,101,-17,27,-24,85,62,-1,2, -5,-1,18,0,57,21,-20,-54,38,88,-1,18, 15,5,64,48,12,62,-127,51,31,23,-12,44, 
  /* [4][2][][] */ 53,5,56,67,61,21,24,-41,11,57,11,-27, 86,51,110,63,-111,16,-68,0,0,119,0,-33, -27,-31,60,29,-66,-8,-120,21,31,88,38,-26, 
  /* [5][0][][] */ -64,67,-28,12,63,-29,-124,56,-76,26,-52,-38, 40,-42,-61,-101,69,79,-113,-42,-68,60,-63,-76, 73,-106,-8,-62,29,-24,-46,89,-67,18,0,-81, 
  /* [5][1][][] */ -31,-93,72,52,-45,-41,-37,-29,-1,52,-90,-84, 36,32,97,-75,74,71,-87,11,-40,-104,-104,-48, 25,-97,15,-78,19,-62,40,-53,15,76,-97,-32, 
  /* [5][2][][] */ -46,-74,-59,-28,22,-27,8,19,-6,34,-29,-85, -91,-94,-103,28,-89,0,-56,83,39,-105,-26,-21, -13,41,24,79,-114,-127,-71,-37,-55,47,-13,-98, 
  /* [6][0][][] */ 127,2,-8,-13,30,-18,51,-47,-12,63,-55,-69, 98,39,15,18,10,-62,0,-33,-14,14,-18,-8, 15,-63,57,-26,-33,-2,6,47,-44,40,-67,5, 
  /* [6][1][][] */ -6,-88,-65,40,5,8,-12,32,-27,-11,65,-27, -13,18,9,76,-25,-25,-114,61,20,60,9,25, -11,-45,21,1,-46,-17,-93,8,-35,-55,26,-11, 
  /* [6][2][][] */ 8,-60,-28,-44,36,60,33,-16,30,37,-35,-47, 61,15,40,37,74,-16,-61,-4,11,42,-66,-38, 42,-61,112,-3,-74,-99,-29,62,18,41,-79,35, 
  /* [7][0][][] */ -87,-27,98,6,-48,75,-91,-15,73,98,55,-24, -10,-13,89,22,30,-22,-121,-27,55,-9,-40,-7, -72,-27,7,-4,20,38,-106,-3,6,7,-38,38, 
  /* [7][1][][] */ -127,7,73,-12,39,4,-70,-60,54,3,66,19, -61,27,114,-23,36,-45,-27,-72,11,71,-54,-60, -28,51,18,-22,-48,16,-99,41,13,88,-49,-11, 
  /* [7][2][][] */ -81,-14,123,46,-68,-16,-48,-4,75,4,17,-55, 42,-45,120,-49,-32,-54,-114,-74,30,59,-19,26, 83,52,41,65,-87,44,-86,68,-58,52,44,-24, 
  /* [8][0][][] */ 33,-48,115,-41,89,-43,14,-37,59,55,-43,20, -36,-37,47,-31,127,62,88,-106,84,75,-25,10, 22,-36,2,24,70,21,0,-34,22,17,4,-58, 
  /* [8][1][][] */ -21,-24,33,64,-32,-66,-104,52,44,21,43,0, 2,28,104,25,-9,-53,3,10,-9,72,95,17, 39,29,-12,68,-40,-41,-124,-45,-23,30,58,-4, 
  /* [8][2][][] */ -28,-119,92,1,-85,-62,-66,48,28,-7,-30,36, -15,-46,57,25,-45,-60,-6,52,-29,-6,15,4, -52,-43,-31,-6,14,30,-8,20,-2,46,15,-25, 
  /* [9][0][][] */ -8,58,-19,-29,23,93,-47,13,-5,-5,-4,13, -5,16,-20,20,-3,105,-11,-15,-22,-1,20,3, -47,43,-41,43,-8,37,-26,33,-38,43,22,6, 
  /* [9][1][][] */ -25,46,-53,-38,22,57,-28,-25,-46,-42,34,-48, -17,51,-5,47,-39,94,-42,-26,-4,54,4,15, -36,34,-11,30,-55,93,-18,-23,-28,-35,24,11, 
  /* [9][2][][] */ -11,25,-51,-2,18,72,-30,-13,-40,-59,28,-41, -4,34,-39,54,-28,123,-23,0,23,3,-28,14, -27,33,19,-12,0,127,-51,17,-30,-10,-24,-23, 
  /* [10][0][][] */ 28,-1,-65,59,21,-127,22,41,20,34,49,-8, 29,21,14,30,-6,-66,51,45,8,-35,35,-59, 28,46,-56,26,-45,-95,36,-44,-25,-38,-10,-9, 
  /* [10][1][][] */ 48,-32,-27,76,-23,-69,-16,67,-72,-46,-58,28, -40,58,-77,79,31,-1,-96,60,-66,-61,17,11, 12,49,-45,37,15,-74,-58,28,12,-75,19,72, 
  /* [10][2][][] */ 2,-36,-93,-15,-21,-80,32,-18,-2,4,-29,-1, -62,-49,-80,57,-45,9,-79,6,-44,-33,-108,36, -32,-55,-34,-38,-34,-69,17,4,48,-41,-103,47, 
  /* [11][0][][] */ -63,32,45,17,66,-28,-32,-12,-19,54,36,19, -58,19,66,-5,76,35,-26,-15,30,35,-1,-29, -42,-4,54,-16,-60,26,-41,11,41,72,4,16, 
  /* [11][1][][] */ -55,32,-5,60,66,27,-45,-5,5,44,-7,12, -31,31,37,10,-38,-34,-32,-27,-3,28,-24,26, -39,-24,66,4,-50,-56,-39,-29,41,35,-29,-46, 
  /* [11][2][][] */ -85,40,-19,27,-14,34,-64,36,-9,30,8,-9, -32,-24,29,6,-51,15,-23,-68,25,42,-3,25, 29,-10,58,23,-30,16,-127,8,16,35,6,23, 
};
const TfArray<4, int> tensor_dimension9 = { 4, { 12,3,3,12 } };
const TfArray<12, float> quant9_scale = { 12, { 0.0025690363254398108, 0.0029834073502570391, 0.0030108890496194363, 0.0026490415912121534, 0.0028561276849359274, 0.0016348622739315033, 0.0036166096106171608, 0.0025606476701796055, 0.0026893822941929102, 0.0046515865251421928, 0.00255949841812253, 0.0037553152069449425, } };
const TfArray<12, int> quant9_zero = { 12, { 0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const ALIGN(16) int32_t tensor_data10[12] = { 13244, -1524, 870, -755, 8108, 1588, 18413, -9659, 2606, 1407, -4972, -9661, };
const TfArray<1, int> tensor_dimension10 = { 1, { 12 } };
const TfArray<12, float> quant10_scale = { 12, { 7.7170952863525599e-06, 9.5399373094551265e-06, 1.1786881259467918e-05, 9.2666796263074502e-06, 1.1952372005907819e-05, 8.7869793787831441e-06, 9.5335026344400831e-06, 9.8434129540692084e-06, 1.1873248695337679e-05, 1.2339333807176445e-05, 1.0968495189445093e-05, 7.8646344263688661e-06, } };
const TfArray<12, int> quant10_zero = { 12, { 0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const ALIGN(16) int8_t tensor_data11[12*3*3*3] = { 
  /* [0][0][][] */ -43,-72,-6, -106,39,64, -57,-103,74, 
  /* [0][1][][] */ 12,-8,-98, -79,-121,-43, -111,24,-44, 
  /* [0][2][][] */ -115,56,-93, 27,-38,68, 49,127,115, 
  /* [1][0][][] */ -98,-25,3, 47,-97,-16, 7,-41,54, 
  /* [1][1][][] */ 44,-15,-127, 97,54,-68, 88,2,-97, 
  /* [1][2][][] */ -31,-92,-32, 92,28,47, -44,-61,-75, 
  /* [2][0][][] */ 31,71,-78, -33,38,-118, 1,-35,-13, 
  /* [2][1][][] */ -41,52,-105, 35,1,-82, -18,31,-55, 
  /* [2][2][][] */ -75,34,-127, -71,51,-126, 24,58,-72, 
  /* [3][0][][] */ -106,-5,-127, 63,98,54, -82,101,-7, 
  /* [3][1][][] */ -102,-6,-42, 43,15,76, -62,59,-1, 
  /* [3][2][][] */ -82,93,34, -36,67,22, -17,16,99, 
  /* [4][0][][] */ 86,35,127, -48,-24,-53, -80,-127,6, 
  /* [4][1][][] */ -43,86,70, -108,-37,-81, -18,-93,24, 
  /* [4][2][][] */ 9,-70,13, -41,-76,-52, -52,27,35, 
  /* [5][0][][] */ 12,-81,40, 115,-116,1, 96,-127,8, 
  /* [5][1][][] */ 124,-62,-33, 31,-36,-2, 45,-96,-84, 
  /* [5][2][][] */ 65,-53,-84, -15,-112,66, -8,-99,-31, 
  /* [6][0][][] */ 22,-68,8, -101,-48,-35, -127,-83,-76, 
  /* [6][1][][] */ -115,-88,-127, -1,94,82, -17,-32,-58, 
  /* [6][2][][] */ -19,-98,-32, -84,-46,-26, -74,32,-1, 
  /* [7][0][][] */ 47,-28,49, -53,-83,100, -50,-85,79, 
  /* [7][1][][] */ 21,9,74, -29,33,94, 71,46,127, 
  /* [7][2][][] */ 63,17,15, 59,66,92, 40,-91,16, 
  /* [8][0][][] */ 32,7,-127, 10,-10,-68, 17,57,-95, 
  /* [8][1][][] */ -11,17,-88, -62,-10,-23, -8,15,-53, 
  /* [8][2][][] */ 19,0,21, -40,57,-82, -20,-11,-14, 
  /* [9][0][][] */ -62,9,-127, 11,75,-33, -20,74,-76, 
  /* [9][1][][] */ -28,-48,-36, 61,-10,-4, -69,-29,-13, 
  /* [9][2][][] */ -32,74,-114, 9,30,-15, -52,62,34, 
  /* [10][0][][] */ 36,-35,-98, -76,2,-123, -18,-32,-127, 
  /* [10][1][][] */ 7,52,87, 15,-28,9, 15,-56,88, 
  /* [10][2][][] */ 3,-13,49, 39,83,52, -53,-30,51, 
  /* [11][0][][] */ -22,38,116, 24,-9,-2, -16,-122,48, 
  /* [11][1][][] */ -37,86,127, 18,-47,105, -30,63,15, 
  /* [11][2][][] */ 85,54,70, 50,21,-65, -21,13,-78, 
};
const TfArray<4, int> tensor_dimension11 = { 4, { 12,3,3,3 } };
const TfArray<12, float> quant11_scale = { 12, { 0.0019678592216223478, 0.0024326839484274387, 0.00300565455108881, 0.0023630030918866396, 0.0030478546395897865, 0.0022406796924769878, 0.0024310429580509663, 0.002510070102289319, 0.0030276782345026731, 0.0031465298961848021, 0.0027969661168754101, 0.0020054816268384457, } };
const TfArray<12, int> quant11_zero = { 12, { 0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1,96,96,12 } };
const TfArray<1, float> quant12_scale = { 1, { 0.006159796379506588, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1,48,48,12 } };
const TfArray<1, float> quant13_scale = { 1, { 0.006159796379506588, } };
const TfArray<1, int> quant13_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<4, int> tensor_dimension14 = { 4, { 1,48,48,12 } };
const TfArray<1, float> quant14_scale = { 1, { 0.0069924700073897839, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<4, int> tensor_dimension15 = { 4, { 1,24,24,12 } };
const TfArray<1, float> quant15_scale = { 1, { 0.0069924700073897839, } };
const TfArray<1, int> quant15_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1,24,24,8 } };
const TfArray<1, float> quant16_scale = { 1, { 0.016112219542264938, } };
const TfArray<1, int> quant16_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<4, int> tensor_dimension17 = { 4, { 1,12,12,8 } };
const TfArray<1, float> quant17_scale = { 1, { 0.016112219542264938, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<4, int> tensor_dimension18 = { 4, { 1,12,12,8 } };
const TfArray<1, float> quant18_scale = { 1, { 0.032247375696897507, } };
const TfArray<1, int> quant18_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&quant18_zero, 0 };
const TfArray<4, int> tensor_dimension19 = { 4, { 1,6,6,8 } };
const TfArray<1, float> quant19_scale = { 1, { 0.032247375696897507, } };
const TfArray<1, int> quant19_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant19 = { (TfLiteFloatArray*)&quant19_scale, (TfLiteIntArray*)&quant19_zero, 0 };
const TfArray<2, int> tensor_dimension20 = { 2, { 1,288 } };
const TfArray<1, float> quant20_scale = { 1, { 0.032247375696897507, } };
const TfArray<1, int> quant20_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant20 = { (TfLiteFloatArray*)&quant20_scale, (TfLiteIntArray*)&quant20_zero, 0 };
const TfArray<2, int> tensor_dimension21 = { 2, { 1,3 } };
const TfArray<1, float> quant21_scale = { 1, { 0.61118882894515991, } };
const TfArray<1, int> quant21_zero = { 1, { 88 } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&quant21_zero, 0 };
const TfArray<2, int> tensor_dimension22 = { 2, { 1,3 } };
const TfArray<1, float> quant22_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant22_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant22 = { (TfLiteFloatArray*)&quant22_scale, (TfLiteIntArray*)&quant22_zero, 0 };
const TfLiteConvParams opdata0 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs0 = { 3, { 0,11,10 } };
const TfArray<1, int> outputs0 = { 1, { 12 } };
const TfLitePoolParams opdata1 = { kTfLitePaddingSame, 2,2, 2,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs1 = { 1, { 12 } };
const TfArray<1, int> outputs1 = { 1, { 13 } };
const TfLiteConvParams opdata2 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs2 = { 3, { 13,9,8 } };
const TfArray<1, int> outputs2 = { 1, { 14 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 2,2, 2,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 14 } };
const TfArray<1, int> outputs3 = { 1, { 15 } };
const TfLiteConvParams opdata4 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs4 = { 3, { 15,7,6 } };
const TfArray<1, int> outputs4 = { 1, { 16 } };
const TfLitePoolParams opdata5 = { kTfLitePaddingSame, 2,2, 2,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs5 = { 1, { 16 } };
const TfArray<1, int> outputs5 = { 1, { 17 } };
const TfLiteConvParams opdata6 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs6 = { 3, { 17,5,4 } };
const TfArray<1, int> outputs6 = { 1, { 18 } };
const TfLitePoolParams opdata7 = { kTfLitePaddingSame, 2,2, 2,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs7 = { 1, { 18 } };
const TfArray<1, int> outputs7 = { 1, { 19 } };
const TfLiteReshapeParams opdata8 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs8 = { 2, { 19,1 } };
const TfArray<1, int> outputs8 = { 1, { 20 } };
const TfLiteFullyConnectedParams opdata9 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs9 = { 3, { 20,3,2 } };
const TfArray<1, int> outputs9 = { 1, { 21 } };
const TfLiteSoftmaxParams opdata10 = { 1 };
const TfArray<1, int> inputs10 = { 1, { 21 } };
const TfArray<1, int> outputs10 = { 1, { 22 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 110592, (TfLiteIntArray*)&tensor_dimension0, 27648, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 12, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant2))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 864, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant3))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant4))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 576, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant5))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 864, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data8, (TfLiteIntArray*)&tensor_dimension8, 48, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data9, (TfLiteIntArray*)&tensor_dimension9, 1296, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data10, (TfLiteIntArray*)&tensor_dimension10, 48, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data11, (TfLiteIntArray*)&tensor_dimension11, 324, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 110592, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 110592, (TfLiteIntArray*)&tensor_dimension13, 27648, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 27648, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 27648, (TfLiteIntArray*)&tensor_dimension15, 6912, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant15))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension16, 4608, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant16))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 4608, (TfLiteIntArray*)&tensor_dimension17, 1152, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant17))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension18, 1152, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant18))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 1152, (TfLiteIntArray*)&tensor_dimension19, 288, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant19))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension20, 288, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant20))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 288, (TfLiteIntArray*)&tensor_dimension21, 3, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant21))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension22, 3, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant22))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs7, (TfLiteIntArray*)&outputs7, const_cast<void*>(static_cast<const void*>(&opdata7)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs8, (TfLiteIntArray*)&outputs8, const_cast<void*>(static_cast<const void*>(&opdata8)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs9, (TfLiteIntArray*)&outputs9, const_cast<void*>(static_cast<const void*>(&opdata9)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs10, (TfLiteIntArray*)&outputs10, const_cast<void*>(static_cast<const void*>(&opdata10)), OP_SOFTMAX, },
};

static void init_tflite_tensor(size_t i, TfLiteTensor *tensor) {
  tensor->type = tensorData[i].type;
  tensor->is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  tensor->allocation_type = tensorData[i].allocation_type;
#else
  tensor->allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
  tensor->bytes = tensorData[i].bytes;
  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(tensor->allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
  tensor->quantization = tensorData[i].quantization;
  if (tensor->quantization.type == kTfLiteAffineQuantization) {
    TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
    tensor->params.scale = quant->scale->data[0];
    tensor->params.zero_point = quant->zero_point->data[0];
  }

}

static void init_tflite_eval_tensor(int i, TfLiteEvalTensor *tensor) {

  tensor->type = tensorData[i].type;

  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  auto allocation_type = tensorData[i].allocation_type;
  if(allocation_type == kTfLiteArenaRw) {
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
    tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
}

static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBufferImpl(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  uint32_t align_bytes = (bytes % 16) ? 16 - (bytes % 16) : 0;

  if (current_location - (bytes + align_bytes) < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  // align to the left aligned boundary of 16 bytes
  current_location -= 15; // for alignment
  current_location += 16 - ((uintptr_t)(current_location) & 15);

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArenaImpl(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBufferImpl(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBufferImpl(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static const uint16_t TENSOR_IX_UNUSED = 0x7FFF;

static void ResetTensors() {
  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    tflTensors[ix].index = TENSOR_IX_UNUSED;
  }
  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    tflEvalTensors[ix].index = TENSOR_IX_UNUSED;
  }
}

static TfLiteTensor* GetTensorImpl(const struct TfLiteContext* context,
                               int tensor_idx) {

  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    // already used? OK!
    if (tflTensors[ix].index == tensor_idx) {
      return &tflTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_tensor(tensor_idx, &tflTensors[ix].tensor);
      tflTensors[ix].index = tensor_idx;
      return &tflTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_TENSOR_COUNT (%d)\n", MAX_TFL_TENSOR_COUNT);
  return nullptr;
}

static TfLiteEvalTensor* GetEvalTensorImpl(const struct TfLiteContext* context,
                                       int tensor_idx) {

  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    // already used? OK!
    if (tflEvalTensors[ix].index == tensor_idx) {
      return &tflEvalTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflEvalTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_eval_tensor(tensor_idx, &tflEvalTensors[ix].tensor);
      tflEvalTensors[ix].index = tensor_idx;
      return &tflEvalTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_EVAL_COUNT (%d)\n", (int)MAX_TFL_EVAL_COUNT);
  return nullptr;
}

class EonMicroContext : public MicroContext {
 public:
  EonMicroContext(): MicroContext(nullptr, nullptr, nullptr) { }

  void* AllocatePersistentBuffer(size_t bytes) {
    return AllocatePersistentBufferImpl(nullptr, bytes);
  };
  TfLiteStatus RequestScratchBufferInArena(size_t bytes,
                                           int* buffer_index) {
  return RequestScratchBufferInArenaImpl(nullptr, bytes, buffer_index);
  }
  void* GetScratchBuffer(int buffer_index) {
    return GetScratchBufferImpl(nullptr, buffer_index);
  }

  TfLiteTensor* AllocateTempTfLiteTensor(int tensor_index) {
    return GetTensorImpl(nullptr, tensor_index);
  }
  void DeallocateTempTfLiteTensor(TfLiteTensor* tensor) {
    return;
  }
  bool IsAllTempTfLiteTensorDeallocated() {
    return true;
  }

  TfLiteEvalTensor* GetEvalTensor(int tensor_index) {
    return GetEvalTensorImpl(nullptr, tensor_index);
  }
};

} // namespace

TfLiteStatus tflite_learn_5_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;

  EonMicroContext micro_context_;
  ctx.impl_ = static_cast<void*>(&micro_context_);
  ctx.AllocatePersistentBuffer = &AllocatePersistentBufferImpl;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArenaImpl;
  ctx.GetScratchBuffer = &GetScratchBufferImpl;
  ctx.GetTensor = &GetTensorImpl;
  ctx.GetEvalTensor = &GetEvalTensorImpl;
  ctx.tensors_size = 23;
  for (size_t i = 0; i < 23; ++i) {
    TfLiteTensor tensor;
    init_tflite_tensor(i, &tensor);
    if (tensor.allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tensor.data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t i = 0; i < 11; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for (size_t i = 0; i < 11; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      ResetTensors();

      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteStatus tflite_learn_5_input(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(inTensorIndices[index], tensor);
  return kTfLiteOk;
}

static const int outTensorIndices[] = {
  22, 
};
TfLiteStatus tflite_learn_5_output(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(outTensorIndices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_5_invoke() {
  for (size_t i = 0; i < 11; ++i) {
    ResetTensors();

    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_5_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
